---
title: "TF-IDF_practice.rmd"
output: html_document
author: "Slimykat"
date: "2018年 4月 9日"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
####<載入封包>
```{r}
library(NLP)
library(readtext)
library(tm)
library(tmcn)
library(jiebaRD)
library(jiebaR)
library(xml2)
library(rvest)
library(stringr)
library(knitr)
library(Matrix)
library(ggplot2)
library(varhandle)
```
#### 1. 進入ptt網站抓取貼文文字
```{r}
#custom option===
end_index = 2411        #最新頁數
start_index = 2356     #最舊頁數
#================程式將會從最舊頁數一直抓到最新頁數

pre_url = "https://www.ptt.cc/bbs/NTU/index"
html_url = ".html"
post_count = c()
guan_count = c()
ptt_text = c()

for(i in c(start_index:end_index)){
  url <- paste0(pre_url, i, html_url)                                                #建立url進入看板NTU
  links_data_title <- read_html(url) %>% html_nodes(".title") %>% html_text()        #抓取標題
  links_data_url <- read_html(url) %>% html_nodes(".title a") %>% html_attr('href')  #抓取標題的連結
  post_count = c(post_count, length(links_data_title))
  links_data_title <- str_replace_all(links_data_title,"\t","") %>% str_replace_all("\n","")
  
  flag = xor(grepl("管",links_data_title)|grepl("校長",links_data_title),      #包含的關鍵字 
             grepl("管理",links_data_title)|grepl("管學院",links_data_title))  #除去的關鍵字
 
  guan_count = c(guan_count , length(links_data_title[flag]))
  
  for(j in (1:length(links_data_title))[flag]){
    links_url = paste0('https://www.ptt.cc',links_data_url[j])
    content_css = read_html(links_url) %>% html_nodes("#main-content") %>% html_text()
    ptt_text = c(ptt_text, iconv(content_css,'utf8'))
  }
}                                                                              #進入每一個貼文中抓取文字
```
#### 2. 清洗、斷詞，依照貼文順序製作TDM
```{r}
data.corpus = Corpus(VectorSource(ptt_text))
data.corpus = tm_map(data.corpus, removePunctuation)
data.corpus = tm_map(data.corpus, removeNumbers)
data.corpus = tm_map(data.corpus, function(word){gsub("[被啊唉礙安吧噓推\n  \t a-zA-Z，。、？！：～ ※→]","",word) })
                                                                               #清除標點符號、數字、以及其他無用字元
mixseg = worker()
keywords = read.csv("keywords.csv",quote = "")
new_user_word(mixseg, as.matrix(keywords))

jieba_tokenizer = function(d){
  unlist( segment(d[[1]], mixseg) )
}
seg = lapply(data.corpus, jieba_tokenizer)

count_token = function(d){
  as.data.frame(table(d))
}
tokens = lapply(seg, count_token)

len = length(seg)
TDM = tokens[[1]]
for( id in c(2:len) ){
  TDM = merge(TDM, tokens[[id]], by='d', all = TRUE)
  names(TDM) = c('d', 1:id)
}
TDM[is.na(TDM)] = 0

tf = rowSums(TDM[,2:len+1])
```
```{r ,echo=FALSE}
kable(head(TDM[,1:31]))
kable(tail(TDM[,1:31]))
```

#### 3. 轉換成TF-IDF
```{r}
idfCal <- function(word_doc){ 
  log2( len / nnzero(word_doc) ) 
}
idf <- apply(as.matrix(TDM[,2:(len+1)]), 1, idfCal)

doc.tfidf <- TDM
token_len = length(idf)

tempY = matrix(rep(c(as.matrix(tf)), each = token_len), nrow = token_len)
tempX = matrix(rep(c(as.matrix(idf)), each = token_len), ncol = token_len, byrow = TRUE)
doc.tfidf[,2:(len+1)] <- (doc.tfidf[,2:(len+1)] / tempY) * tempX
for(id in c(2:len+1)){
  doc.tfidf[!is.finite(doc.tfidf[,id]) , id] = 0
}
stopLine = rowSums(doc.tfidf[,2:(len+1)])
delID = which(stopLine == 0)
```
#### 4. 擷取出重要字串
```{r}
doc.tfidf = doc.tfidf[-delID,]
TopWords = data.frame()
for( id in c(1:len) ){
  Max = order(doc.tfidf[,id+1], decreasing = TRUE)
  showResult = t(as.data.frame(doc.tfidf[Max[1:10],1]))
  TopWords = rbind(TopWords, showResult)
}
rownames(TopWords) = colnames(doc.tfidf)[2:(len+1)]
TopWords = droplevels(TopWords)
```
```{r, echo = F}
kable(head(TopWords))
kable(tail(TopWords))
```
#### 5. 貼文內容關鍵字詞以及其變化
```{r}
TopNo = 8                          #擷取前10筆資料
TDM$d = as.character(TDM$d)
AllTop = as.data.frame( table(as.matrix(TopWords)) )
AllTop = AllTop[order(AllTop$Freq, decreasing = TRUE),]
tempGraph = data.frame()
for( t in c(1:TopNo) ){
  word = matrix( rep(c(as.matrix(AllTop$Var1[t])), each = len), nrow = len )
  temp = cbind( colnames(doc.tfidf)[2:(len+1)], t(TDM[which(TDM$d == AllTop$Var1[t]), 2:(len+1)]), word )
  colnames(temp) = c("post", "freq", "words")
  tempGraph = rbind(tempGraph, temp)
  names(tempGraph) = c("post", "freq", "words")
}
tempGraph$freq = unfactor(tempGraph$freq)

ggplot(tempGraph, aes(post, freq)) + 
  geom_point(aes(color = words, shape = words), size = 3) +
  theme(axis.line = element_line(size = 1, colour = "black")) +
  theme(axis.text = element_blank()) +
  theme(axis.ticks = element_blank()) +
  theme(text = element_text(family = "STHeitiTC-Light")) +
  geom_line(aes(group = words, linetype = words))
```

#### 6. 相關貼文出現頻率變化
```{r}
post_freq = guan_count / post_count
post = c(start_index:end_index)
freqGraph = data.frame(post,post_freq)
ggplot(freqGraph, aes(x = post, y = post_freq)) + 
  theme(axis.line = element_line(size = 1, colour = "black")) +
  geom_line()
```
